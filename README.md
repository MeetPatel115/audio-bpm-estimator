# 🎵 Beat Per Minute Prediction

Predict **Beats Per Minute (BPM)** from audio-related features using classic ML models.  
This repo includes **EDA → Feature Engineering → Model Training → Test Prediction** in a single Jupyter notebook.

## 📂 Project Structure
```
.
├── Day2_annotated.ipynb   # Notebook with comments for every step
├── train.csv              # Training dataset (features + target BeatsPerMinute)
├── test.csv               # Test dataset (features only)
├── sample_submission.csv  # Expected submission format
├── submission1.csv        # Predictions generated by the notebook
├── requirements.txt       # Python dependencies
└── README.md              # Project documentation
```

## 🧠 Problem
Given tabular features describing tracks, predict the **`BeatsPerMinute`** for each record in the test set.

## 🛠️ Setup
```bash
git clone <your-repo-url>
cd <your-repo-folder>
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

pip install -r requirements.txt
```

## 🚀 Run
Open the notebook and execute cells top-to-bottom:
```bash
jupyter notebook Day2_annotated.ipynb
```
This will:
1. Load `train.csv` and `test.csv`
2. Perform EDA
3. Apply feature engineering (`create_features`)
4. Split into train/validation (80/20)
5. Train a baseline model (e.g., Linear Regression, Random Forest)
6. Evaluate with **RMSE** and **R²**
7. Generate `submission1.csv` with columns: `id, BeatsPerMinute`

## 📊 Notes on Modeling
- Baseline uses **Linear Regression** (change to **RandomForestRegressor** / **GradientBoostingRegressor** to compare)
- Metric: **RMSE** (lower is better), **R²** (closer to 1 is better)
- You can add cross-validation and hyperparameter tuning for stronger results

## 🧩 Feature Engineering (examples)
- `Rhythm_Audio_Interaction = RhythmScore * AudioLoudness`
- `Vocal_Acoustic_Ratio = VocalContent / AcousticQuality` (handle division by zero)
- Median imputation for missing numeric values

## 🔮 Next Improvements
- Hyperparameter tuning (Random Forest / XGBoost / LightGBM)
- Feature importance analysis; drop noisy features
- K-fold cross-validation for robustness
- Try regularized linear models (Ridge/Lasso) and SVR

## 📦 Dependencies
See `requirements.txt` (generated from notebook imports), including:
- pandas, numpy, matplotlib, seaborn
- scikit-learn, scipy
- ipykernel for Jupyter

## 👤 Author
**Meet Patel** — Toronto, ON

---
If you find this useful, ⭐ the repo and open an issue/PR with suggestions!
